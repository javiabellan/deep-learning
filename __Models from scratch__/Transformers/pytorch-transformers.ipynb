{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version:      1.2.0\n",
      "Transformers version: 1.2.0\n",
      "\n",
      "GPU available: True\n",
      "GPU name:      GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(\"Pytorch version:     \", torch.__version__)\n",
    "print(\"Transformers version:\", pytorch_transformers.__version__)\n",
    "print(\"\")\n",
    "print(\"GPU available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:     \", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Transformer-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pytorch_transformers.TransfoXLTokenizer.from_pretrained('transfo-xl-wt103')\n",
    "model     = pytorch_transformers.TransfoXLModel.from_pretrained('transfo-xl-wt103')\n",
    "modelLM   = pytorch_transformers.TransfoXLLMHeadModel.from_pretrained('transfo-xl-wt103')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pytorch_transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model     = pytorch_transformers.GPT2Model.from_pretrained('gpt2')\n",
    "modelLM   = pytorch_transformers.GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pytorch_transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model     = pytorch_transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "modelLM   = pytorch_transformers.BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: BERT multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 995526/995526 [00:00<00:00, 1178839.72B/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 521/521 [00:00<00:00, 261297.67B/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 714314041/714314041 [01:29<00:00, 7957622.98B/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = pytorch_transformers.BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model     = pytorch_transformers.BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "modelLM   = pytorch_transformers.BertForMaskedLM.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: XLM multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 2952532/2952532 [00:01<00:00, 2579497.52B/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1434601/1434601 [00:00<00:00, 1625326.66B/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 775/775 [00:00<00:00, 88552.51B/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1385437546/1385437546 [05:15<00:00, 4385069.04B/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = pytorch_transformers.XLMTokenizer.from_pretrained('xlm-mlm-xnli15-1024')\n",
    "model     = pytorch_transformers.XLMModel.from_pretrained('xlm-mlm-xnli15-1024')\n",
    "modelLM   = pytorch_transformers.XLMWithLMHeadModel.from_pretrained('xlm-mlm-xnli15-1024')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pytorch_transformers.RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model     = pytorch_transformers.RobertaModel.from_pretrained('roberta-base')\n",
    "modelLM   = pytorch_transformers.RobertaForMaskedLM.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pytorch_transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model     = pytorch_transformers.DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "modelLM   = pytorch_transformers.DistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ĠMe', 'Ġgust', 'an', 'Ġlos', 'Ġtacos', ',', 'Ġy', 'Ġte', 'Ġqu', 'ier', 'o'],\n",
       " [2185, 35253, 272, 22346, 44058, 11, 331, 573, 627, 959, 78])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I have two dogs and one dog is a puppeteer\"\n",
    "text = \"Me llamo Juan y me gustan las\"\n",
    "text = \"Me gustan los tacos, y te quiero\"\n",
    "\n",
    "tokens_text       = tokenizer.tokenize(text)\n",
    "tokens_ids        = tokenizer.convert_tokens_to_ids(tokens_text)\n",
    "tokens_ids_tensor = torch.tensor([tokens_ids])\n",
    "tokens_text, tokens_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertor size: 768\n"
     ]
    }
   ],
   "source": [
    "print(\"vertor size:\", model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "outputs = model(tokens_ids_tensor)[0]\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some next token prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = model(tokens_ids_tensor)[0]\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
    "predicted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'age'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_text = tokenizer.decode([predicted_index])\n",
    "predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1045, 2031, 2048, 6077, 1998, 2028, 2003, 1037]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text      = \"I have two dogs and one is a\"\n",
    "input     = torch.tensor([tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))])\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'puppy'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################# OLD\n",
    "text      = \"I have two dogs and one is a\"\n",
    "input     = torch.tensor([tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))])\n",
    "next_word = torch.argmax(model(input)[0][0, -1])\n",
    "tokenizer.convert_ids_to_tokens([next_word.item()])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
