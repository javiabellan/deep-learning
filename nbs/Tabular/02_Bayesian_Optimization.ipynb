{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Bayesian Optimization\n",
    "\n",
    "In this notebook, we'll look at how to apply baysian optimization onto `fastai2` tabular problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Bayesian Optimization?\n",
    "\n",
    "* Form of hyper-parameter tuning\n",
    "* Repository for today: [BayesianOptimization](https://github.com/fmfn/BayesianOptimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian optimization works by constructing a posterior distribution of functions (gaussian process) that best describes the function you want to optimize. As the number of observations grows, the posterior distribution improves, and the algorithm becomes more certain of which regions in parameter space are worth exploring and which are not, as seen in the picture below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://camo.githubusercontent.com/2f66986b9b375058dcaede2e7c3dd2b8db4abc9d/68747470733a2f2f6769746875622e636f6d2f666d666e2f426179657369616e4f7074696d697a6174696f6e2f7261772f6d61737465722f6578616d706c65732f626f5f6578616d706c652e706e67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastai2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's get the items we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's install the `bayesian-optimization` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bayesian-optimization -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with `BayesianOpimization`, everything needs to be in a `fit_with` function that accepts our tuned parameters, and does whatever we require of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_with(lr:float, wd:float, dp:float):\n",
    "  # create a Learner\n",
    "  config = tabular_config({'emb_p':dp,\n",
    "                          'wd':wd})\n",
    "  learn = tabular_learner(data, layers=[200,100], metrics=accuracy, config=config)\n",
    "  \n",
    "  # Train for x epochs\n",
    "  with learn.no_bar():\n",
    "    learn.fit_one_cycle(3, lr)\n",
    "    \n",
    "  # Save, print, and return the overall accuracy\n",
    "  acc = float(learn.validate()[1])\n",
    "  \n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's adjust this further to show how we would go about adjusting the learning rate, embedded weight decay, drop out, and layer size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_with(lr:float, wd:float, dp:float, n_layers:float, layer_1:float, layer_2:float, layer_3:float):\n",
    "\n",
    "  print(lr, wd, dp)\n",
    "  if int(n_layers) == 2:\n",
    "    layers = [int(layer_1), int(layer_2)]\n",
    "  elif int(n_layers) == 3:\n",
    "    layers = [int(layer_1), int(layer_2), int(layer_3)]\n",
    "  else:\n",
    "    layers = [int(layer_1)]\n",
    "  config = tabular_config({'emb_p':float(dp),\n",
    "                          'wd':float(wd)})\n",
    "  learn = tabular_learner(dls, layers=layers, metrics=accuracy, config = config)\n",
    "\n",
    "  with learn.no_bar() and learn.no_logging():\n",
    "    learn.fit(5, lr=float(lr))\n",
    "\n",
    "  acc = float(learn.validate()[1])\n",
    "\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "y_names = 'salary'\n",
    "y_block = CategoryBlock()\n",
    "splits = RandomSplitter()(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TabularPandas(df, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                   y_names=y_names, y_block=y_block, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = to.dataloaders(bs=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll declare our hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = {'lr': (1e-05, 1e-01),\n",
    "      'wd': (4e-4, 0.4),\n",
    "      'dp': (0.01, 0.5),\n",
    "       'n_layers': (1,3),\n",
    "       'layer_1': (50, 200),\n",
    "       'layer_2': (100, 1000),\n",
    "       'layer_3': (200, 2000)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we build the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = BayesianOptimization(\n",
    "    f = fit_with, # our fit function\n",
    "    pbounds = hps, # our hyper parameters to tune\n",
    "    verbose = 2, # 1 prints out when a maximum is observed, 0 for silent\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    dp     |  layer_1  |  layer_2  |  layer_3  |    lr     | n_layers  |    wd     |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "0.014684121522803134 0.07482958046651729 0.21434078230426126\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8398  \u001b[0m | \u001b[0m 0.2143  \u001b[0m | \u001b[0m 158.0   \u001b[0m | \u001b[0m 100.1   \u001b[0m | \u001b[0m 744.2   \u001b[0m | \u001b[0m 0.01468 \u001b[0m | \u001b[0m 1.185   \u001b[0m | \u001b[0m 0.07483 \u001b[0m |\n",
      "0.06852509784467198 0.3512957275818218 0.1793247562510934\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8383  \u001b[0m | \u001b[0m 0.1793  \u001b[0m | \u001b[0m 109.5   \u001b[0m | \u001b[0m 584.9   \u001b[0m | \u001b[0m 954.6   \u001b[0m | \u001b[0m 0.06853 \u001b[0m | \u001b[0m 1.409   \u001b[0m | \u001b[0m 0.3513  \u001b[0m |\n",
      "0.014047289990137426 0.32037752964274446 0.02341992066698382\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8371  \u001b[0m | \u001b[0m 0.02342 \u001b[0m | \u001b[0m 150.6   \u001b[0m | \u001b[0m 475.6   \u001b[0m | \u001b[0m 1.206e+0\u001b[0m | \u001b[0m 0.01405 \u001b[0m | \u001b[0m 1.396   \u001b[0m | \u001b[0m 0.3204  \u001b[0m |\n",
      "0.0894617202837497 0.016006291379859792 0.4844481721025048\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8279  \u001b[0m | \u001b[0m 0.4844  \u001b[0m | \u001b[0m 97.01   \u001b[0m | \u001b[0m 723.1   \u001b[0m | \u001b[0m 1.778e+0\u001b[0m | \u001b[0m 0.08946 \u001b[0m | \u001b[0m 1.17    \u001b[0m | \u001b[0m 0.01601 \u001b[0m |\n",
      "0.0957893741197487 0.27687409473460917 0.09321690558663875\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8193  \u001b[0m | \u001b[0m 0.09322 \u001b[0m | \u001b[0m 181.7   \u001b[0m | \u001b[0m 188.5   \u001b[0m | \u001b[0m 958.0   \u001b[0m | \u001b[0m 0.09579 \u001b[0m | \u001b[0m 2.066   \u001b[0m | \u001b[0m 0.2769  \u001b[0m |\n",
      "0.010278165724320144 0.09525641811550664 0.039180893394315415\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8395  \u001b[0m | \u001b[0m 0.03918 \u001b[0m | \u001b[0m 169.8   \u001b[0m | \u001b[0m 995.0   \u001b[0m | \u001b[0m 206.4   \u001b[0m | \u001b[0m 0.01028 \u001b[0m | \u001b[0m 1.351   \u001b[0m | \u001b[0m 0.09526 \u001b[0m |\n",
      "0.0721697277771627 0.035039066808375346 0.1710613610736308\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.8404  \u001b[0m | \u001b[95m 0.1711  \u001b[0m | \u001b[95m 57.63   \u001b[0m | \u001b[95m 100.2   \u001b[0m | \u001b[95m 1.93e+03\u001b[0m | \u001b[95m 0.07217 \u001b[0m | \u001b[95m 2.868   \u001b[0m | \u001b[95m 0.03504 \u001b[0m |\n",
      "0.01869849193249724 0.3818035749775107 0.38248534044728827\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8322  \u001b[0m | \u001b[0m 0.3825  \u001b[0m | \u001b[0m 69.48   \u001b[0m | \u001b[0m 104.2   \u001b[0m | \u001b[0m 1.936e+0\u001b[0m | \u001b[0m 0.0187  \u001b[0m | \u001b[0m 2.247   \u001b[0m | \u001b[0m 0.3818  \u001b[0m |\n",
      "0.01926217459495932 0.09147910397966807 0.12524115091042773\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8366  \u001b[0m | \u001b[0m 0.1252  \u001b[0m | \u001b[0m 57.32   \u001b[0m | \u001b[0m 188.9   \u001b[0m | \u001b[0m 206.0   \u001b[0m | \u001b[0m 0.01926 \u001b[0m | \u001b[0m 2.35    \u001b[0m | \u001b[0m 0.09148 \u001b[0m |\n",
      "0.06351398588490466 0.04037129713639955 0.24616817310336075\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8325  \u001b[0m | \u001b[0m 0.2462  \u001b[0m | \u001b[0m 52.86   \u001b[0m | \u001b[0m 992.5   \u001b[0m | \u001b[0m 1.125e+0\u001b[0m | \u001b[0m 0.06351 \u001b[0m | \u001b[0m 1.886   \u001b[0m | \u001b[0m 0.04037 \u001b[0m |\n",
      "0.041377735497824156 0.06620056537013629 0.32676614140212673\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8352  \u001b[0m | \u001b[0m 0.3268  \u001b[0m | \u001b[0m 54.51   \u001b[0m | \u001b[0m 114.5   \u001b[0m | \u001b[0m 1.363e+0\u001b[0m | \u001b[0m 0.04138 \u001b[0m | \u001b[0m 1.901   \u001b[0m | \u001b[0m 0.0662  \u001b[0m |\n",
      "0.0758754095037137 0.26350352166402036 0.10013698396219092\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8342  \u001b[0m | \u001b[0m 0.1001  \u001b[0m | \u001b[0m 195.5   \u001b[0m | \u001b[0m 166.4   \u001b[0m | \u001b[0m 236.0   \u001b[0m | \u001b[0m 0.07588 \u001b[0m | \u001b[0m 1.276   \u001b[0m | \u001b[0m 0.2635  \u001b[0m |\n",
      "0.09389439425982331 0.19684544787061198 0.15110795801308013\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8331  \u001b[0m | \u001b[0m 0.1511  \u001b[0m | \u001b[0m 52.28   \u001b[0m | \u001b[0m 999.6   \u001b[0m | \u001b[0m 1.971e+0\u001b[0m | \u001b[0m 0.09389 \u001b[0m | \u001b[0m 1.358   \u001b[0m | \u001b[0m 0.1968  \u001b[0m |\n",
      "0.05628262681087503 0.1085257299138718 0.26772478114338355\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8348  \u001b[0m | \u001b[0m 0.2677  \u001b[0m | \u001b[0m 152.2   \u001b[0m | \u001b[0m 105.5   \u001b[0m | \u001b[0m 755.5   \u001b[0m | \u001b[0m 0.05628 \u001b[0m | \u001b[0m 2.52    \u001b[0m | \u001b[0m 0.1085  \u001b[0m |\n",
      "0.053434289309203895 0.16031684438917504 0.38333589370592197\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8315  \u001b[0m | \u001b[0m 0.3833  \u001b[0m | \u001b[0m 191.2   \u001b[0m | \u001b[0m 972.2   \u001b[0m | \u001b[0m 674.7   \u001b[0m | \u001b[0m 0.05343 \u001b[0m | \u001b[0m 2.787   \u001b[0m | \u001b[0m 0.1603  \u001b[0m |\n",
      "=============================================================================================================\n",
      "CPU times: user 1min 11s, sys: 2.01 s, total: 1min 13s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%time optim.maximize(n_iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can grab the best results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.8404483795166016, 'params': {'dp': 0.1710613610736308, 'layer_1': 57.63154958927875, 'layer_2': 100.1567384765859, 'layer_3': 1930.4092799350558, 'lr': 0.0721697277771627, 'n_layers': 2.868052690189961, 'wd': 0.035039066808375346}}\n"
     ]
    }
   ],
   "source": [
    "print(optim.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with a few conversions we see:\n",
    "\n",
    "* The best number of layers was 2\n",
    "* The first layer a size of 57\n",
    "* The second layer a size of 100\n",
    "And then of course our other hyper paramters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
